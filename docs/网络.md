8.22:
    1.tcp握手
        TCP三次握手是建立可靠连接的机制：
        
        **第一次握手（SYN）**：
        - 客户端发送SYN包，seq=x，请求建立连接
        - 客户端进入SYN_SENT状态
        
        **第二次握手（SYN+ACK）**：
        - 服务器收到SYN包，发送SYN+ACK包
        - seq=y, ack=x+1，确认收到客户端请求
        - 服务器进入SYN_RCVD状态
        
        **第三次握手（ACK）**：
        - 客户端发送ACK包，seq=x+1, ack=y+1
        - 确认收到服务器响应
        - 双方进入ESTABLISHED状态，连接建立
        
        **为什么需要三次握手？**
        - 防止失效连接请求被服务器接受
        - 确保双方都能发送和接收数据
        - 同步双方的序列号
        
        **四次挥手断开连接**：
        - FIN → ACK → FIN → ACK
        - 确保数据完全传输完毕再断开

    2.在开发阶段，建议加上时间消耗记录

    3.如何保证服务器的服务不中断，中断了如何处理
        **预防服务中断的策略**：
        
        **1. 高可用架构**：
        - 负载均衡（Load Balancer）
        - 多服务器部署（集群）
        - 数据库主从复制
        - CDN内容分发
        
        **2. 容错机制**：
        - 健康检查（Health Check）
        - 自动故障转移（Failover）
        - 熔断器模式（Circuit Breaker）
        - 重试机制（Retry Logic）
        
        **3. 监控告警**：
        - 服务器资源监控（CPU、内存、磁盘）
        - 应用性能监控（响应时间、错误率）
        - 日志监控和分析
        - 实时告警系统
        
        **4. 容器化部署**：
        ```yaml
        # Docker Compose 示例
        version: '3.8'
        services:
          app:
            image: myapp:latest
            replicas: 3
            restart: always
            healthcheck:
              test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
              interval: 30s
              timeout: 10s
              retries: 3
        ```
        
        **服务中断后的处理**：
        
        **1. 立即响应**：
        - 自动切换到备用服务器
        - 启用降级服务（基本功能）
        - 通知用户当前状态
        
        **2. 问题诊断**：
        - 查看监控数据和日志
        - 确定故障原因和影响范围
        - 评估修复时间
        
        **3. 服务恢复**：
        - 修复根本问题
        - 逐步恢复服务
        - 数据一致性检查
        - 性能验证
        
        **4. 事后总结**：
        - 故障复盘分析
        - 改进预防措施
        - 更新应急预案

8.23： 
    1.http长轮询
        HTTP长轮询是实现服务器推送的技术之一：    
        **工作原理**：
        - 客户端发送请求到服务器
        - 服务器保持连接打开，不立即响应
        - 有数据更新时才返回响应
        - 客户端收到响应后立即发起新的请求
        
        **优点**：
        - 实现简单，兼容性好
        - 相比短轮询减少请求数量
        - 数据实时性较好
        
        **缺点**：
        - 服务器资源占用（长连接）
        - 网络异常处理复杂
        - 不如WebSocket高效
        
        **适用场景**：
        - 聊天应用
        - 实时通知
        - 股票价格更新
        - 系统状态监控

    2.服务器发送事件SSE
        SSE（Server-Sent Events）是HTML5标准，用于服务器向客户端推送数据：
        
        **特点**：
        - 单向通信（服务器→客户端）
        - 基于HTTP协议
        - 自动重连机制
        - 支持事件类型
  
        **与其他技术对比**：
        
        | 技术 | 通信方向 | 协议 | 复杂度 | 兼容性 |
        |------|----------|------|--------|--------|
        | SSE  |    单向  | HTTP  | 简单 | 好 |
        | WebSocket| 双向  | WS   | 中等 | 好 |
        | 长轮询   | 双向  | HTTP | 简单 | 最好 |
        
        **适用场景**：
        - 实时数据展示（股票、监控）
        - 消息通知推送
        - 直播弹幕
        - 系统日志实时显示
        - 进度条更新

    3.容器化部署能够实现服务不中断主要是通过以下几个核心机制：
        滚动更新 (Rolling Updates),在新容器启动并健康检查通过后，才关闭旧容器
        多实例部署 + 负载均衡
        蓝绿部署 (Blue-Green Deployment)
        容器编排的优势

8.24
    1.储存桶和数据库存数据有什么区别
    选择存储桶服务当：
        存储大文件（图片、视频、文档）
        需要 CDN 加速访问
        静态资源托管
        备份和归档需求
        对象存储 - 以文件/对象的形式存储数据
        非结构化数据 - 主要存储图片、视频、文档、备份等
        简单的键值结构 - 通过唯一的 key 来访问对象
        HTTP/REST API - 通过 URL 直接访问
    选择数据库服务当：
        需要复杂查询和数据分析
        数据之间有关联关系
        需要事务保证
        实时数据更新频繁
        结构化数据 - 以表格、文档或图形结构存储
        复杂查询 - 支持 SQL 查询、索引、事务
        数据关系 - 支持表之间的关联查询
        ACID 特性 - 保证数据一致性和完整性

        大多数现代应用都是混合使用：
            数据库 存储结构化的业务数据
            存储桶 存储文件和静态资源
            数据库中存储文件的 URL 来建立关联

8.30：
    1.接口失效
        LTS版本问题、 http版本、 抓包处理

9.1：
    1.cookie是什么

    2.HTTP headers理论上不区分大小写，但签名算法对此很敏感。

9.11：
    1.网路层级

# cors原理

# sse协议

URL编码



TCP连接
一、 单个服务器能连接多少客户端
 
理论上，单个服务器能承载的TCP客户端连接数，核心受 文件描述符限制 和 端口/IP资源约束 两个因素影响：
 
文件描述符（FD）限制
操作系统中，每个TCP连接对应一个文件描述符，而系统对进程能打开的文件描述符数量有默认上限（比如Linux默认可能是1024）。通过调整系统参数（如 ulimit 、 /etc/security/limits.conf ），可以大幅提升这个上限，理论上能达到数万甚至数十万。
 
IP与端口的约束
服务器端的连接是**“服务器IP+服务器监听端口+客户端IP+客户端端口”** 四元组唯一标识的。服务器监听端口固定（如80、8080），但客户端的IP和端口是可变的，因此只要服务器资源足够，不会被端口数量限制，真正的瓶颈是服务器的内存、CPU和带宽。
 
实际场景中，普通服务器一般能稳定承载 数万到十几万 并发连接，高性能服务器（多核+大内存）可支撑 几十万甚至百万级 并发，具体取决于业务逻辑的复杂度。
 
二、 多个客户端并发连接的处理方案
 
服务器处理多客户端并发，核心是解决 “如何高效响应多个连接的请求” 问题，主流有3种模型，各有适用场景：
 
多进程/多线程模型
 
- 原理：服务器每接收到一个客户端连接，就创建一个新的进程或线程专门处理该连接的通信。
 
- 特点：逻辑简单，开发成本低；但进程/线程的创建和切换开销大，并发量高时（如上万）会消耗大量CPU和内存，容易出现性能瓶颈。
 
I/O多路复用模型（主流）
 
- 原理：用单个或少量线程，通过  select/poll/epoll（Linux）  或  kqueue（BSD）  等系统调用，同时监听多个连接的I/O事件（如“有数据可读”“有连接请求”），只有当连接有事件发生时才去处理。
 
- 特点：资源消耗极低，能高效支撑数万到数十万并发，是高性能服务器（如Nginx、Redis）的核心方案。
 
异步I/O模型
 
- 原理：服务器发起I/O操作后，不用阻塞等待结果，而是继续处理其他任务，等I/O操作完成后，操作系统会通过回调或信号通知服务器处理结果。
 
- 特点：理论上并发性能最高，但编程模型复杂，对开发能力要求高。
 
需要我帮你整理这三种并发模型的优缺点对比表，方便你快速选型吗？






HTTP/1.1、HTTP/2、HTTP/3 版本对比
快速对比
特性	HTTP/1.1	HTTP/2	HTTP/3
发布年份	1997	2015	2022
传输层	TCP	TCP	QUIC (UDP)
多路复用	❌	✅	✅
头部压缩	❌	HPACK	QPACK
服务器推送	❌	✅	✅
队头阻塞	TCP + HTTP层	TCP层	❌ 无
连接建立	1-2 RTT	1-2 RTT	0-1 RTT
数据格式	文本	二进制	二进制
架构演进
HTTP/1.1                HTTP/2                  HTTP/3┌──────────┐           ┌──────────┐           ┌──────────┐│  HTTP    │           │  HTTP/2  │           │  HTTP/3  │├──────────┤           ├──────────┤           ├──────────┤│   TLS    │ (可选)    │   TLS    │ (必须)    │   QUIC   │ ← 内置TLS├──────────┤           ├──────────┤           │  (UDP)   ││   TCP    │           │   TCP    │           └──────────┘└──────────┘           └──────────┘
HTTP/1.1 详解
特点
文本协议: 人类可读，但解析效率低
持久连接: Keep-Alive 复用TCP连接
管道化: 可发送多个请求，但响应必须按序返回
主要问题
请求1 ──────────────────────────────────────▶ 响应1       请求2（等待响应1完成）──────────────▶ 响应2              请求3（等待响应2完成）──────▶ 响应3问题：队头阻塞（Head-of-Line Blocking）
常见优化手段
域名分片（多个TCP连接）
资源合并（雪碧图、文件打包）
内联资源
HTTP/2 详解
核心特性
1. 多路复用 (Multiplexing)
单一TCP连接:┌─────────────────────────────────────────┐│  Stream 1 (HTML)   ████░░░░████░░░░████ ││  Stream 2 (CSS)    ░░████░░░░████░░░░░░ ││  Stream 3 (JS)     ░░░░████░░░░████░░░░ ││  Stream 4 (Image)  ████░░████░░░░████░░ │└─────────────────────────────────────────┘多个请求/响应可以交错传输，互不阻塞
2. 二进制分帧
HTTP/1.1 文本格式:GET /index.html HTTP/1.1Host: example.comHTTP/2 二进制帧:┌────────────┬──────────┬─────────────┐│ Length (3) │ Type (1) │ Flags (1)   │├────────────┴──────────┴─────────────┤│ Stream Identifier (4)               │├─────────────────────────────────────┤│ Frame Payload (variable)            │└─────────────────────────────────────┘
3. 头部压缩 (HPACK)
第一次请求::method: GET:path: /index.html:authority: example.comcookie: user=abc123...后续请求（只发送差异部分）::path: /style.css    ← 其他头部复用静态表/动态表压缩率可达 85-90%
4. 服务器推送
客户端请求 index.html    ↓服务器返回 index.html    ↓ (主动推送)服务器推送 style.css服务器推送 app.js减少请求往返次数
HTTP/2 的局限
TCP层队头阻塞: 单个TCP连接丢包会阻塞所有流
握手延迟: TCP + TLS 需要 2-3 RTT
连接迁移困难: 网络切换时需要重建连接
HTTP/3 详解
核心改变：QUIC协议
QUIC = UDP + 可靠传输 + 多路复用 + TLS 1.3┌─────────────────────────────────────────┐│              HTTP/3                      │├─────────────────────────────────────────┤│              QUIC                        ││  ┌─────────┬─────────┬─────────────────┐││  │可靠传输  │多路复用  │   TLS 1.3      │││  └─────────┴─────────┴─────────────────┘│├─────────────────────────────────────────┤│              UDP                         │└─────────────────────────────────────────┘
关键优势
1. 消除队头阻塞
HTTP/2 (TCP):流1 [████]     ← 丢包，所有流等待重传流2 [等待...]流3 [等待...]HTTP/3 (QUIC):流1 [████]     ← 丢包，只影响流1流2 [████████] ← 继续传输流3 [████████] ← 继续传输
2. 更快的连接建立
TCP + TLS 1.2:     3 RTTTCP + TLS 1.3:     2 RTTQUIC 首次连接:     1 RTTQUIC 0-RTT 恢复:   0 RTT  ← 极速！
3. 连接迁移
场景：手机从 WiFi 切换到 4GHTTP/2: WiFi连接断开 → 重新TCP握手 → 重新TLS握手 → 继续传输(用户感知：卡顿/中断)HTTP/3:使用 Connection ID 标识连接IP变化 → 连接无缝迁移 → 继续传输(用户感知：无中断)
4. 改进的拥塞控制
在用户空间实现，更易迭代优化
支持多种拥塞控制算法
更精确的RTT测量
性能对比
理想场景（低延迟、无丢包）
HTTP/1.1  ████████████████████  100%HTTP/2    ████████             40%HTTP/3    ███████              35%
高丢包场景（2%丢包率）
HTTP/1.1  ████████████████████████████  140%HTTP/2    ████████████████████████      120%HTTP/3    ████████████                  60%  ← 优势明显
高延迟场景（200ms RTT）
首次加载时间:HTTP/1.1  ████████████████████  100%HTTP/2    ████████████          60%HTTP/3    ██████████            50%
实际部署建议
选择 HTTP/1.1
简单的内部服务
兼容性要求高
调试需求（文本可读）
选择 HTTP/2
现代Web应用（主流选择）
CDN/反向代理
移动端应用
选择 HTTP/3
全球用户（高延迟地区）
移动端（网络切换频繁）
实时性要求高
需要最优性能
检测方式
// 浏览器中检查协议版本// 开发者工具 → Network → Protocol 列// Node.js 服务端const http2 = require('http2');const server = http2.createSecureServer({  key: fs.readFileSync('key.pem'),  cert: fs.readFileSync('cert.pem')});
总结
版本	一句话描述
HTTP/1.1	串行处理，简单可靠，效率较低
HTTP/2	多路复用，二进制高效，但受TCP限制
HTTP/3	基于QUIC，彻底解决队头阻塞，面向未来
演进趋势: HTTP/3 是未来方向，目前 Google、Facebook、Cloudflare 等已广泛部署。





TCP字节流的数据传输机制
TCP只提供字节流，所有的消息结构都需要应用层定义。
🔍 数据在哪里？
发送端（项圈）：
char message[] = "IDENTIFY:CE:96:C2:78:27:FC\n";
send(socket, message, strlen(message), 0);
数据位置：程序内存中的字符数组
网络传输：
TCP数据包结构：
┌─────────────┬──────────────────────────────────┐
│   TCP头部   │        数据载荷(Payload)          ││   
(20字节)       │   I D E N T I F Y : C E : 9 6... │  
└─────────────┴──────────────────────────────────┘
数据位置：TCP包的payload部分，纯字节序列
接收端（服务器）：
socket.on('data', (buffer: Buffer) => {  // buffer 就是字节流数据  const message = buffer.toString('utf8');  console.log('收到字节:', buffer);        // <Buffer 49 44 45 4e 54...>  console.log('解析文本:', message);       // "IDENTIFY:CE:96:C2:78:27:FC\n"});
数据位置：Node.js的Buffer对象中
🔄 TCP的"无结构"特性
TCP不知道消息含义：
TCP眼中看到的：
[字节] [字节] [字节] [字节] [字节] [字节] [字节]...  
73     68     101    108    108    111    10  
|      |      |      |      |      |      |  
s      h      e      l      l      o     
\n应用层看到的："IDENTIFY:CE:96:C2:78:27:FC\n" → 身份识别消息
应用层负责解析：
// TCP只管传输字节socket.on('data', (data) => {  
    const rawBytes = data.toString();    
    // 应用层解析消息格式  const lines = rawBytes.split('\n');  
    for (const line of lines) {    
        if (line.startsWith('IDENTIFY:')) {      
            const mac = line.split(':')[1];      
            // 处理身份识别    
            }  
        }});
🧩 消息边界问题
TCP的挑战：
发送方：send("HELLO");  send("WORLD");接收方可能收到：情况1: "HELLO" + "WORLD"  (粘包)情况2: "HEL" + "LOWORLD" (分包)
我们的解决方案：
使用换行符\n作为消息边界："IDENTIFY:CE:96:C2:78:27:FC\n""location\n"
💡 总结
TCP字节流特点：
✅ 只管传输：TCP负责可靠传输字节序列
❌ 不管含义：不知道字节代表什么意思
❌ 不管边界：不知道消息在哪里开始和结束
应用层职责：
定义消息格式（如何组织字节）
解析消息含义（字节代表什么命令）
处理消息边界（如何分割不同消息）
所以是的，所有数据都在字节流中，应用层负责理解和解析



TCP数据包结构详解
是的，TCP数据包确实只包含两个主要部分：
┌─────────────────┬─────────────────────────────┐│    TCP头部      │         TCP载荷             ││   (20-60字节)   │      (应用数据)             │└─────────────────┴─────────────────────────────┘
📋 TCP头部内容（协议控制信息）
固定部分（20字节）：
字段	字节数	作用
源端口号	2	发送方端口
目标端口号	2	接收方端口
序列号	4	数据包顺序编号
确认号	4	确认收到的数据编号
头长度+标志	2	头部长度、SYN/ACK/FIN等标志
窗口大小	2	流量控制
校验和	2	错误检测
紧急指针	2	紧急数据指示
可选部分（0-40字节）：
时间戳选项
窗口缩放选项
其他TCP扩展选项
📊 实际数据示例
项圈发送身份识别：
TCP头部（20字节）：┌──────┬──────┬────────┬────────┬──────┬──────┬──────┬──────┐
│源端口│目标端│序列号   │确认号  │标志位│窗口  │校验和│紧急  ││ 3572 │ 3001 │12345678│87654321│ ACK │ 1024 │0x1234│  0   │└──────┴──────┴────────┴────────┴──────┴──────┴──────┴──────┘TCP载荷（26字节）："IDENTIFY:CE:96:C2:78:27:FC\n"
总包大小：20 + 26 = 46字节（不含IP头部）



实际网络传输确实包含很多额外信息，recv() 会自动剥离协议头部。
📦 完整数据包的实际传输
网络上的真实数据包：
┌──────────┬──────────┬──────────┬──────────────┐
│ 以太网头 │  IP头部  │ TCP头部  │   应用数据   │
│ 14字节   │ 20字节   │ 20字节   │  "location"  │
│          │          │          │   8字节      │
└──────────┴──────────┴──────────┴──────────────┘
总计：14 + 20 + 20 + 8 = 62字节在网络上传输
发送8字节"location"，实际网络传输62字节！
🏗️ 操作系统网络栈的自动处理
分层处理过程：
应用层(你的代码)：   send("location", 8)         ↓传输层(TCP)：      添加TCP头部 (20字节)         ↓  网络层(IP)：       添加IP头部 (20字节)         ↓数据链路层：       添加以太网头部 (14字节)          ↓物理层：          电信号传输                  [网络传输]         物理层：          接收电信号         ↑数据链路层：       处理以太网帧，剥离以太网头部         ↑网络层(IP)：       处理IP包，剥离IP头部           ↑传输层(TCP)：      处理TCP段，剥离TCP头部         ↑应用层(你的代码)：   recv() → "location" (8字节)
💻 recv() 的自动处理
操作系统为您做的事：
// 你写的代码char buffer[1024];int len = recv(socket, buffer, sizeof(buffer), 0);// 操作系统实际做的事：// 1. 从网络接收62字节数据包// 2. 剥离以太网头部(14字节) → 48字节  // 3. 剥离IP头部(20字节) → 28字节// 4. 剥离TCP头部(20字节) → 8字节// 5. 验证校验和、序列号等// 6. 只把应用数据(8字节)给你的程序// 你的buffer里只有干净的应用数据buffer = "location"  // 8字节纯数据
🔒 连接隔离保证
多连接示例：
网络上同时传输：包1: [以太网][IP][TCP:端口3001][项圈A的"location"]包2: [以太网][IP][TCP:端口3001][项圈B的"status"] 包3: [以太网][IP][TCP:端口3000][APP的HTTP请求]操作系统自动分发：- 端口3001连接A → recv() 收到 "location"- 端口3001连接B → recv() 收到 "status"  - 端口3000连接C → recv() 收到 HTTP数据





TCP 连接断开感知机制
核心结论
断开方式	主动断开方	被动方能否感知
正常关闭	✅ 知道	✅ 能立即感知
进程崩溃	✅ 知道	✅ 能立即感知
主机崩溃	✅ 知道	❌ 不能感知
网络中断	❌ 双方都不知道	❌ 不能感知
拔网线	❌ 双方都不知道	❌ 不能感知
各种断开场景详解
场景1: 正常关闭 ✅
客户端                              服务端   │                                   │   │─────── FIN ──────────────────────▶│  客户端发起关闭   │◀────── ACK ───────────────────────│  服务端确认   │◀────── FIN ───────────────────────│  服务端也关闭   │─────── ACK ──────────────────────▶│  客户端确认   │                                   │   双方都能正常感知连接关闭
场景2: 进程崩溃/被杀死 ✅
客户端进程崩溃      │      ▼操作系统接管 ──▶ 自动发送 FIN/RST 给对方      │      ▼服务端收到后立即感知连接断开
进程退出时，OS 会清理该进程的所有文件描述符（包括socket）
OS 会代替进程发送 FIN 或 RST 包
对方能立即感知
场景3: 主机崩溃（断电/死机）❌
客户端                              服务端   │                                   │   │       ← 正常通信中 →               │   │                                   │   ⚡ 突然断电                          │   X                                   │ (完全不知道)                                       │ (连接状态仍显示ESTABLISHED)                                       │ (直到尝试发送数据...)
问题:
断电的主机无法发送任何数据包
对方完全不知道连接已经失效
连接会保持 ESTABLISHED 状态（可能永远）
场景4: 网络中断（路由器故障/拔网线）❌
客户端                   [断开]           服务端   │                      ✂️               │   │        网络不通                       │   │                                       │ 双方都不知道           双方都不知道 连接其实已无效         连接其实已无效
问题:
双方的 TCP 栈都认为连接正常
只有在尝试发送数据时才会发现问题
如果双方都不发数据，可能永远不知道




TCP 心跳数据与业务数据的关系
问题1: 是否需要发送数据才能检测断开？
是的！ TCP 本身不会主动检测连接状态。
连接建立后:客户端 ←─────────────────────────────────→ 服务端       │  双方都在等待对方发数据...          │       │  如果双方都不发，永远不知道断了      │       │                                    │       │  只有发送数据时才能发现:            │       │  - ACK 超时重传失败 → 断开          │       │  - 收到 RST 包 → 断开               │
问题2: 心跳数据会与业务数据冲突吗？
两种心跳的区别
类型	数据位置	是否影响业务	粘包问题
TCP Keep-Alive	TCP层（无应用数据）	❌ 不影响	❌ 不存在
应用层心跳	应用层（有数据）	⚠️ 需要设计	⚠️ 需要处理
TCP Keep-Alive（系统级）
正常数据包:┌──────────────────────────────────────────────┐│ IP头 │ TCP头 │ 应用数据 (payload)            │└──────────────────────────────────────────────┘Keep-Alive 探测包:┌──────────────────────────────────────────────┐│ IP头 │ TCP头 │ (无数据，seq=上次ACK的seq-1)  │└──────────────────────────────────────────────┘特点:- 在 TCP 层处理，应用层完全无感知- 不携带任何应用数据- 不会产生粘包/分包问题- 应用程序 read() 不会读到任何东西
应用层心跳（需要协议设计）
业务数据和心跳数据混在一起发送:┌─────────────────────────────────────────────────────┐│ 心跳包 │ 业务数据 │ 业务数据 │ 心跳包 │ 业务数据    │└─────────────────────────────────────────────────────┘         ↓    TCP 发送时可能:         ↓┌───────────────────┐  ┌─────────────────────────────┐│ 心跳包+半个业务... │  │ ...剩余业务+心跳+业务...     │└───────────────────┘  └─────────────────────────────┘     包1（粘包）              包2（粘包+分包