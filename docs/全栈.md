
# 概念解释
限流（Rate Limiting）
是什么：限制单位时间内的请求量（按用户/接口/IP/Token 等维度）。
为什么：防止突发流量把系统打挂，保护下游依赖。
常见方式：令牌桶、漏桶、固定窗口/滑动窗口；返回 429 Too Many Requests。
熔断（Circuit Breaker）
是什么：当某个下游服务持续失败/超时，就“暂时断开调用”，快速失败一段时间。
为什么：避免故障扩散、线程/连接耗尽，给下游恢复时间。
典型状态：Closed（正常）→ Open（断开）→ Half-Open（试探恢复）。
链路追踪（Distributed Tracing）
是什么：给一次请求在多个服务间的调用打上 TraceId，记录每一段耗时与错误。
为什么：定位“慢在哪里/错在哪里”（网关→服务A→DB→服务B…）。
常见术语：Trace（一次请求）、Span（一个调用片段）。
容量规划（Capacity Planning）
是什么：估算需要多少机器/实例/数据库资源来扛住目标流量，并留冗余。
为什么：避免高峰崩溃或过度采购浪费。
典型输入：QPS、平均/峰值、P95 延迟、CPU/内存、水位线、扩容策略。
ETL（Extract-Transform-Load）
是什么：把数据从来源抽取（E）、清洗/转换（T）、加载到目标库（L）。
为什么：把“脏、散、格式不一”的业务数据变成可分析可用的数据。
数据仓库（Data Warehouse）
是什么：面向分析的集中式数据存储（强调历史、可追溯、面向主题）。
为什么：支持统一口径的报表、指标与多维分析。
常见分层：ODS（原始）/DWD（明细）/DWS（汇总）/ADS（应用）。
批处理 / 流处理（Batch / Stream Processing）
批处理：按小时/天处理一批数据（延迟高但简单稳定）。
流处理：数据一来就处理（延迟低，适合实时监控/实时推荐）。
指标体系（Metrics System）
是什么：定义公司/业务“怎么看数据”的统一口径（如 DAU、留存、转化率）。
为什么：避免各算各的、口径不一致导致决策错误。
关键点：指标定义、计算逻辑、维度、口径变更管理。
报表（BI Reports）
是什么：把指标与维度以可视化方式呈现（图表、看板、日报周报）。
为什么：让业务快速看趋势、发现异常、评估策略效果。
数据建模（Data Modeling）
是什么：为了查询与分析，把数据组织成更好用的结构。
常见模型：
星型模型：事实表（交易/行为）+ 维度表（用户/时间/地区）
雪花模型：维度进一步规范化拆分
SQL 优化（DBA/数据库工程常见工作之一）
是什么：让查询更快、更稳、更省资源。
常见手段：建索引、避免全表扫描、改写 SQL、分库分表、慢查询治理、参数与连接池调优、Explain 分析执行计划。
召回（Retrieval）
是什么：从海量候选里“先捞一批可能相关的”（几百/几千）。
目标：快、覆盖率高（宁可多一点候选）。
排序（Ranking）
是什么：对候选集按“最可能喜欢/最可能点击/最可能转化”排序。
目标：准（效果好），通常计算更重。
特征工程（Feature Engineering）
是什么：把用户、内容、上下文变成模型可用的特征（如近7天点击次数、品类偏好）。
在深度学习里也会弱化手工特征，但“特征/信号”仍是核心。
在线服务（Online Serving）
是什么：把推荐/排序模型部署成线上服务，能在毫秒级返回结果。
关注：低延迟、高可用、可扩展、版本管理。
A/B 实验（AB Testing）
是什么：把用户随机分组，对比策略A和B对关键指标的提升。
关注：随机分流、样本量、显著性、实验污染、指标选择。
Docker
是什么：把应用和依赖打包成镜像，保证“到哪都能跑”。
价值：环境一致、交付标准化、易部署。
K8s（Kubernetes）
是什么：容器编排系统，自动部署、扩缩容、滚动更新、自愈。
价值：稳定运行大规模服务，标准化运维。
服务治理（Service Governance）
是什么：让微服务“更稳定、更可控”的一系列能力。
常见能力：注册发现、限流熔断、重试超时、负载均衡、降级、配置、灰度、观测。
Service Mesh（服务网格）
是什么：把“服务间通信能力”（鉴权、限流、重试、观测等）下沉到基础设施层（sidecar/代理）。
价值：业务代码更干净，治理能力统一，但引入复杂度与成本。
Linux / 网络协议 / 性能调优
Linux：理解进程、线程、文件、网络、内存、IO 等系统行为。
网络协议：TCP/UDP/HTTP/HTTPS、连接建立、拥塞控制、重传、Keep-Alive 等。
性能调优：定位瓶颈（CPU/内存/IO/网络/锁/GC），用工具与指标驱动优化（不是凭感觉）。
系统编程（C/C++/Rust）
是什么：更贴近操作系统与硬件，关注内存管理、并发、性能、跨平台。
常见领域：高性能网络库、数据库内核、中间件、客户端引擎、嵌入式。
内存 / 并发 / 跨平台（系统编程核心主题）
内存：堆/栈、指针/所有权、泄漏、碎片、缓存局部性。
并发：线程/协程、锁、无锁、竞态、死锁。
跨平台：不同 OS API/ABI、构建链、兼容性与性能差异。
音视频：编码、渲染、实时传输（WebRTC）、延迟与抖动
编码（Encode）：把原始音视频压缩成 H.264/H.265/Opus 等码流（省带宽）。
渲染（Render）：把解码后的帧画到屏幕/把音频播放出来（同步与不卡顿很关键）。
WebRTC：实时音视频通信技术栈（NAT穿透、拥塞控制、抖动缓冲、回声消除等）。
延迟：端到端从采集到播放的时间；实时场景越低越好。
抖动（Jitter）：网络时延不稳定导致的卡顿/断续；用抖动缓冲、重传、码率自适应等缓解。
图形/渲染：OpenGL / Metal / Vulkan
是什么：底层图形 API，用 GPU 高效绘制图形。
差异（直觉）：
OpenGL：跨平台、历史久。
Metal：苹果平台高性能图形 API。
Vulkan：更底层、更可控、性能潜力大但更复杂。
性能与特效：粒子、后处理、阴影、模糊、动画流畅度等。
嵌入式 / IoT
设备端：在资源受限的硬件上开发（MCU/传感器/网关）。
协议：设备通信协议（如 MQTT、CoAP、BLE 等）。
低功耗：睡眠唤醒、功耗预算、采样频率与传输策略。
边缘计算：在设备/网关侧做计算，减少云端压力与网络依赖。
AI 工程（工程化）
是什么：把模型“变成稳定可用的线上能力”。
典型工作：模型服务化、推理加速、弹性扩缩、监控告警、评测与回归、数据闭环（线上反馈→再训练/再评估）。
推理加速（Inference Acceleration）
是什么：让模型跑得更快、更省钱。
常见手段：量化、剪枝、蒸馏、TensorRT/ONNX、批处理、缓存、多卡并行。
监控 / 评测 / 数据闭环
监控：延迟、吞吐、错误率、成本、质量指标。
评测：离线基准集 + 线上 A/B + 回归测试，防止“变快但变差”。
闭环：收集真实使用数据与反馈，改数据→改模型→再上线。
NLP / CV / 推荐算法（研究/算法）
NLP：自然语言处理（文本理解、生成、检索）。
CV：计算机视觉（识别、检测、分割、跟踪）。
推荐算法（研究）：更偏模型结构、损失函数、特征表示、训练策略与效果提升。
特点：对数学、建模与实验能力要求更高。
LLM 应用开发：RAG、Agent、评测体系、数据治理
RAG（Retrieval-Augmented Generation）：先检索知识（文档/数据库/向量库），再让大模型基于检索结果生成回答，减少幻觉、增强可控性。
Agent：让模型能“规划步骤 + 调用工具/接口 + 迭代执行”，完成多步任务（如查数据→计算→生成报告）。
评测体系：定义质量标准（正确性、引用、覆盖率、鲁棒性）、构建评测集与自动化回归，确保迭代不退化。
数据治理：数据清洗、去重、分级权限、版本管理、隐私合规、知识更新与过期处理。
